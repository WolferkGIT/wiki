# Useful stuff

### Learning resources
* Stanford [cs224n](http://web.stanford.edu/class/cs224n/index.html) "Natural Language Processing with Deep Learning" class and their [video lectures](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z) (highly recommend)
* Stanford [cs231n](http://cs231n.github.io/) notes about neural networks
* [fast.ai](https://www.fast.ai/) - hipster courses on deep learning, pretty good ones
* [BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)
* [Deep Learning Book](https://www.deeplearningbook.org/)

### Libraries and services
* HuggingFace [Transformers](https://github.com/huggingface/transformers) and [Tokenizers](https://github.com/huggingface/tokenizers)
* [Knock Knock](https://github.com/huggingface/knockknock) - get notified when your training ends with only two additional lines of code
* [Weights and Biases](https://www.wandb.com) - the best way to monitor your experiments (bye tensorboard!)
* [tqdm](https://github.com/tqdm/tqdm) - a very simple, fast and extensible progress bar for python and CLI
* [NVIDIA Apex](https://github.com/NVIDIA/apex) - easy way to use [Mixed Precision](https://medium.com/@jonathan_hui/mixed-precision-in-deep-learning-67f6dce3e0f3) (use it if you're out of GPU memory)

### Blogs and other stuff
* [Arxiv CS.CL twitter](https://twitter.com/arxiv_cs_cl) - an infinite stream of fresh papers, perfect in the morning
    * [Arxiv-sanity](http://www.arxiv-sanity.com/search?q=cs.CL) - a tool that helps you to keep track of new staff and to stay sane
* [PyTorch blog on Medium](https://medium.com/pytorch)
* [Facebook AI Research blog](https://ai.facebook.com/blog/)
* [Distill.pub](https://distill.pub) - an excellent journal with visualizations of difficult NN concepts
* [Inference](https://www.inference.vc) - posts on machine learning, statistics, opinions on things (more about the theoretical side)
* [Off the convex path](http://www.offconvex.org/) - deep learning theory blog
* [Towardsdatascience](https://towardsdatascience.com) - a good blog about DS
* [Kaggle](https://kaggle.com) - data science competitions (with free GPUs!)
    * [kaggle.com/notebooks](https://kaggle.com/notebooks) - a lot of examples and how-tos for basically anything
* [Google Colaboratory](https://colab.research.google.com) - a (heavily modified by Google) jupyter notebook server with a free GPU and **TPU**; not very useful, but a free TPU is a free TPU (50 Gb of RAM and blazing fast)
* [TensorFlow Research Cloud](https://www.tensorflow.org/tfrc) - a Google initiative that sponsors cool research projects with free TPU-hours in GCP, apply if you want to pre-train something huge
* [ruder.io](https://ruder.io) - Sebastian Ruder blog
    * [Ruder Newsletter](https://ruder.io/nlp-news/) - concise monthly reviews of NLP state
* [Paperswithcode](https://paperswithcode.com) - an awesome aggregator of papers and GitHub repositories
    * [paperswithcode.com/sota](https://paperswithcode.com/sota) - leaderboard aggregator, pretty good for finding datasets
* [PhDcomics](http://phdcomics.com/) - they know that feel bro
